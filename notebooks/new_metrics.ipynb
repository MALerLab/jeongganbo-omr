{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dongmin/userdata/jeongganbo-omr\n"
     ]
    }
   ],
   "source": [
    "%cd /home/dongmin/23FW-NCG/jeongganbo-omr\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongmin/.local/share/virtualenvs/jeongganbo-omr-QQMBMPoZ/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import csv\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "from random import randint, choice, uniform, seed\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from exp_utils import JeongganSynthesizer, get_img_paths\n",
    "from exp_utils.model_zoo import OMRModel, TransformerOMR\n",
    "from exp_utils.train_utils import Trainer, Dataset, Tokenizer, pad_collate, LabelStudioDataset, draw_low_confidence_plot\n",
    "\n",
    "dprint = lambda d: print(json.dumps(d, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline mock-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data_set loading...\n",
      "COMPLETE: data_set loading\n",
      "\n",
      "load tokenizer\n",
      "COMPLETE: load tokenizer\n",
      "\n",
      "model initializing...\n",
      "COMPLETE: model initializing\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPELETE: Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# random seed setting\n",
    "project_root_dir = Path('.')\n",
    "output_dir = project_root_dir / 'outputs'\n",
    "\n",
    "dir_date = '2024-05-04'\n",
    "dir_time = '20-31-38'\n",
    "\n",
    "exp_dir = output_dir / dir_date / dir_time\n",
    "\n",
    "conf = OmegaConf.load(exp_dir / '.hydra' / 'config.yaml')\n",
    "device = torch.device(conf.general.device)\n",
    "\n",
    "print('\\ndata_set loading...')\n",
    "\n",
    "note_img_path_dict = get_img_paths(project_root_dir / 'test/synth/src', ['notes', 'symbols'])\n",
    "\n",
    "test_set = LabelStudioDataset(project_root_dir / conf.data_path.test, project_root_dir / 'jeongganbo-png/splited-pngs', remove_borders=conf.test_setting.remove_borders, is_valid=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1000, shuffle=False, collate_fn=pad_collate, num_workers=conf.dataloader.num_workers_load)\n",
    "\n",
    "print('COMPLETE: data_set loading')\n",
    "\n",
    "model_dir = exp_dir / 'model'\n",
    "\n",
    "print('\\nload tokenizer')\n",
    "\n",
    "tokenizer_vocab_fn = model_dir / f'{conf.general.model_name}_tokenizer.txt'\n",
    "tokenizer = Tokenizer(vocab_txt_fn=tokenizer_vocab_fn)\n",
    "\n",
    "print('COMPLETE: load tokenizer')\n",
    "\n",
    "print('\\nmodel initializing...')\n",
    "model = TransformerOMR(conf.model.dim, len(tokenizer.vocab), enc_depth=conf.model.enc_depth, dec_depth=conf.model.dec_depth, num_heads=conf.model.num_heads, dropout=conf.model.dropout)\n",
    "model.load_state_dict(torch.load(model_dir / f'{conf.general.model_name}_HL_{conf.test_setting.target_metric}_best.pt', map_location='cpu')['model'])\n",
    "\n",
    "tester = Trainer(model, \n",
    "                 None, #optimizer\n",
    "                 None, #loss_fn\n",
    "                 None, #train_loader\n",
    "                 test_loader, \n",
    "                 tokenizer,\n",
    "                 device=device, \n",
    "                 scheduler=None,\n",
    "                 aux_loader=None,\n",
    "                 aux_freq=None,\n",
    "                 mix_aux=None,\n",
    "                 aux_valid_loader=None,\n",
    "                 wandb=None, \n",
    "                 model_name=conf.general.model_name,\n",
    "                 model_save_path=model_dir,\n",
    "                 checkpoint_logger=None)\n",
    "\n",
    "print('COMPLETE: model initializing')\n",
    "\n",
    "print('\\nTesting...')\n",
    "\n",
    "_, _, pred_tensor_list, confidence_tensor_list = tester.validate(with_confidence=True)\n",
    "\n",
    "print('COMPELETE: Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "\n",
    "for b_idx in range(len(pred_tensor_list)):\n",
    "  pred_list += pred_tensor_list[b_idx].tolist()\n",
    "\n",
    "pred_list = list( enumerate(pred_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_specials = lambda seq: list( map(int, filter( lambda x: x not in (0, 1, 2), seq )) )\n",
    "\n",
    "def calc_acc(gt, prd):\n",
    "  gt, prd = torch.tensor(gt, dtype=torch.long), torch.tensor(prd, dtype=torch.long)\n",
    "  \n",
    "  if prd.shape[0] > gt.shape[0]:\n",
    "    prd = prd[:gt.shape[0]]\n",
    "  elif prd.shape[0] < gt.shape[0]:\n",
    "    prd = torch.cat([prd, torch.zeros(gt.shape[0] - prd.shape[0])], dim=-1)\n",
    "  \n",
    "  num_tokens = gt.shape[0]\n",
    "  num_match_token = prd == gt\n",
    "  num_match_token = num_match_token[gt != 0].sum().item()\n",
    "  \n",
    "  return num_match_token / num_tokens\n",
    "\n",
    "def make_gt_pred_tuple_list(ls):\n",
    "  tup_list = []\n",
    "  \n",
    "  for didx, pred in ls:\n",
    "    img, label = test_set.get_item_by_idx(didx)\n",
    "    \n",
    "    label_enc = tokenizer(label)[1:-1]\n",
    "    pred = filter_specials(pred)\n",
    "    \n",
    "    acc = calc_acc(label_enc, pred)\n",
    "    \n",
    "    tup_list.append( (didx, img, label_enc, pred, acc) )\n",
    "  \n",
    "  return tup_list\n",
    "\n",
    "pred_list = make_gt_pred_tuple_list(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1281"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_long = list( filter( lambda x: len(x[2]) > 2, pred_list ) )\n",
    "\n",
    "len(pred_list_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_long = sorted(pred_list_long, key=lambda x: x[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "test_ls = []\n",
    "\n",
    "for i in range(11):\n",
    "  f = [t for t in pred_list_long if t[4] < (i + 1)*0.1 and t[4] > i*0.1]\n",
    "  test_ls += [choice(f)] if len(f) > 0 else []\n",
    "\n",
    "len(test_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (5, 10), (7, 14)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip([1, 5, 7], [2, 10, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(402,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [119, 34, 12, 3, 4, 14, 3, 89, 16, 3, 121, 18],\n",
       "  [119, 12, 3, 4, 14, 3, 89, 16, 3, 121, 18],\n",
       "  0.08333333333333333),\n",
       " (1218,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [76, 52, 6, 3, 127, 58, 7],\n",
       "  [76, 6, 3, 127, 58, 7],\n",
       "  0.14285714285714285),\n",
       " (1333,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [140, 12, 3, 4, 15, 3, 127, 49, 18],\n",
       "  [140, 6, 3, 127, 49, 7],\n",
       "  0.2222222222222222),\n",
       " (1356,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [140, 55, 15],\n",
       "  [140, 15],\n",
       "  0.3333333333333333),\n",
       " (370,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [80, 12, 3, 4, 14, 3, 87, 57, 16, 3, 83, 18],\n",
       "  [80, 57, 12, 3, 4, 14, 3, 87, 16, 3, 83, 18],\n",
       "  0.4166666666666667),\n",
       " (1494,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [140, 12, 3, 4, 57, 15, 3, 106, 18],\n",
       "  [140, 57, 12, 3, 4, 15, 3, 106, 18],\n",
       "  0.5555555555555556),\n",
       " (951,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [140, 67, 15],\n",
       "  [140, 68, 15],\n",
       "  0.6666666666666666),\n",
       " (1247,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [127, 12, 3, 4, 15, 3, 4, 17, 3, 141, 47, 19],\n",
       "  [127, 12, 3, 4, 15, 3, 4, 17, 3, 87, 19],\n",
       "  0.75),\n",
       " (1529,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [4, 12, 3, 4, 57, 15, 3, 127, 18],\n",
       "  [4, 12, 3, 4, 57, 15, 3, 127, 64, 18],\n",
       "  0.8888888888888888),\n",
       " (1347,\n",
       "  array([[[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       "  \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]]], dtype=uint8),\n",
       "  [105, 12, 3, 4, 14, 3, 127, 16, 3, 105, 17, 3, 140, 55, 19],\n",
       "  [105, 12, 3, 4, 14, 3, 127, 16, 3, 4, 17, 3, 140, 55, 19, 3, 83],\n",
       "  0.9333333333333333)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metrics\n",
    "* NER: note error rate\n",
    "* PER: position error rate\n",
    "* NPER: note-position pair error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 2), (2, 3), (3, 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( map(lambda et: (et[0], et[1]), enumerate([1, 2, 3, 4]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'느'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'느나니'[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청남_노네:2 -:4 니나*:6 청임:8\n",
      "[('_노네', '2')]\n",
      "[('_노네', '청남', '2')]\n",
      "\n",
      "고_덧길이표:10 태_반길이표:11\n",
      "[('_덧길이표', '10'), ('_반길이표', '11')]\n",
      "[('_덧길이표', '고', '10'), ('_반길이표', '태', '11')]\n",
      "\n",
      "황:2 -:5 태_니레:8\n",
      "[('_니레', '8')]\n",
      "[('_니레', '태', '8')]\n",
      "\n",
      "황_루러표:5\n",
      "[('_루러표', '5')]\n",
      "[('_루러표', '황', '5')]\n",
      "\n",
      "노:2 -:4 니_미는표:6 느나:8\n",
      "[('_미는표', '6')]\n",
      "[('_미는표', '니', '6')]\n",
      "\n",
      "황:2 -_미는표:5 배중:8\n",
      "[('_미는표', '5')]\n",
      "[('_미는표', '-', '5')]\n",
      "\n",
      "황_자출:5\n",
      "[('_자출', '5')]\n",
      "[('_자출', '황', '5')]\n",
      "\n",
      "태:2 -:5 -:7 흘림표_니:9\n",
      "[('_니', '9')]\n",
      "[('_니', '흘림표', '9')]\n",
      "\n",
      "-:2 -_미는표:5 태:8\n",
      "[('_미는표', '5')]\n",
      "[('_미는표', '-', '5')]\n",
      "\n",
      "배임:2 -:4 태:6 배임:7 황_루러표:9\n",
      "[('_루러표', '9')]\n",
      "[('_루러표', '황', '9')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_notes_and_positions(label):\n",
    "  pattern = r'([^_\\s:]+|_+[^_\\s:]+|:\\d+|[-])'\n",
    "  \n",
    "  def clean_findings(fds):\n",
    "    int_idx = []\n",
    "    \n",
    "    for i, t in enumerate(fds):\n",
    "      try:\n",
    "        int(t[1:]) # if str p cannot be cast into integer goto except block\n",
    "        int_idx.append(i)\n",
    "      except:\n",
    "        pass\n",
    "    \n",
    "    if len(int_idx) < 1:\n",
    "      return [fds]\n",
    "    \n",
    "    split_fds = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in int_idx:\n",
    "      end_idx = i + 1\n",
    "      split_fds.append(fds[start_idx:end_idx])\n",
    "      start_idx = end_idx\n",
    "    \n",
    "    return split_fds\n",
    "\n",
    "  token_groups = label.split()\n",
    "\n",
    "  notes = []\n",
    "  positions = []\n",
    "  ornaments = []\n",
    "\n",
    "  for group in token_groups:\n",
    "    findings = re.findall(pattern, group)\n",
    "    findings = clean_findings(findings)\n",
    "    \n",
    "    for fd in findings:\n",
    "      note = fd[0]\n",
    "      position = fd[-1]\n",
    "      ornament = fd[1:-1]\n",
    "      \n",
    "      if note[0] == '_':\n",
    "        ornament = [note] + ornament\n",
    "        note = '<pad>'\n",
    "        \n",
    "      notes.append(note)\n",
    "      positions.append(position[1:])\n",
    "      ornaments.append(ornament)\n",
    "\n",
    "  return notes, positions, ornaments\n",
    "\n",
    "for test_case in test_ls:\n",
    "  label, pred = test_case[2:4]\n",
    "  \n",
    "  label_dec = tokenizer.decode( label )\n",
    "  pred_dec = tokenizer.decode( pred )\n",
    "  \n",
    "  label_note, label_pos, label_ornament = get_notes_and_positions(label_dec)\n",
    "  pred_note, pred_pos, pred_ornament = get_notes_and_positions(pred_dec)\n",
    "  \n",
    "  label_note_pos = list( zip(label_note, label_pos) )\n",
    "  pred_note_pos = list( zip(pred_note, pred_pos) )\n",
    "  \n",
    "  map_ornamnet_pos = lambda ol, pl: [(o, p) for i, p in enumerate(pl) for o in ol[i]]\n",
    "  map_ornament_note_pos = lambda ol, tl: [ (o, *t) for i, t in enumerate(tl) for o in ol[i]]\n",
    "  \n",
    "  print(label_dec)\n",
    "  print(map_ornamnet_pos(label_ornament, label_pos))\n",
    "  print(map_ornament_note_pos(label_ornament, label_note_pos))\n",
    "  \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임_노니로:1 중:3 -:5 무_느니-르_노니로:8_느니-르_노니로:8\n",
      "(['임', '중', '-', '무', '<pad>'], ['1', '3', '5', '8', '8'], [['_노니로'], [], [], ['_느니-르', '_노니로'], ['_느니-르', '_노니로']])\n",
      "황:1 태:3 -:5 -:7 배임_노니로:9_노니로:9\n",
      "(['황', '태', '-', '-', '배임', '<pad>'], ['1', '3', '5', '7', '9', '9'], [[], [], [], [], ['_노니로'], ['_노니로']])\n",
      "황:1 태:3 -_흘림표:5 -:8 니:9니:9\n",
      "(['황', '태', '-', '-', '니', '니'], ['1', '3', '5', '8', '9', '9'], [[], [], ['_흘림표'], [], [], []])\n",
      "태:1 황:3 -:4 니:6 배남_흘림표:8_흘림표:8\n",
      "(['태', '황', '-', '니', '배남', '<pad>'], ['1', '3', '4', '6', '8', '8'], [[], [], [], [], ['_흘림표'], ['_흘림표']])\n"
     ]
    }
   ],
   "source": [
    "test_lbs = [\n",
    "  '임_노니로:1 중:3 -:5 무_느니-르_노니로:8_느니-르_노니로:8',\n",
    "  '황:1 태:3 -:5 -:7 배임_노니로:9_노니로:9',\n",
    "  '황:1 태:3 -_흘림표:5 -:8 니:9니:9',\n",
    "  '태:1 황:3 -:4 니:6 배남_흘림표:8_흘림표:8',\n",
    "]\n",
    "\n",
    "for lb in test_lbs:\n",
    "  print(lb)\n",
    "  print(get_notes_and_positions(lb))\n",
    "\n",
    "# print(test_lbs[2])\n",
    "# get_notes_and_positions(test_lbs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 0.999999995) ['고', '태'] ['고', '태']\n",
      "(1.0, 1.0, 0.999999995) ['10', '11'] ['10', '11']\n",
      "(1.0, 1.0, 0.999999995) [('고', '10'), ('태', '11')] [('고', '10'), ('태', '11')]\n",
      "(1.0, 0.5, 0.6666666622222223) ['_덧길이표', '_반길이표'] ['_반길이표']\n",
      "(1.0, 0.5, 0.6666666622222223) [('_덧길이표', '10'), ('_반길이표', '11')] [('_반길이표', '11')]\n",
      "(1.0, 0.5, 0.6666666622222223) [('_덧길이표', '고', '10'), ('_반길이표', '태', '11')] [('_반길이표', '태', '11')]\n"
     ]
    }
   ],
   "source": [
    "def filter_pos_list(pl):\n",
    "  pl_f = []\n",
    "  \n",
    "  for p in pl:\n",
    "    try:\n",
    "      int(p) # if str p cannot be cast into integer goto except block\n",
    "      pl_f.append(p)\n",
    "    except:\n",
    "      pass\n",
    "  \n",
    "  return pl_f\n",
    "\n",
    "\n",
    "def tok2idx_list(tl, is_pos=False):\n",
    "  prefix = ':' if is_pos else '' \n",
    "  return [ tokenizer.tok2idx[prefix + t] for t in tl ]\n",
    "\n",
    "def calc_metric(gt, prd): # +) [꾸밈](GT 꾸밈 0개 이상일 때), [꾸밈, 위치], [본음, 꾸밈, 위치]\n",
    "  gt_tok_dict = defaultdict(int)\n",
    "  \n",
    "  for tok in gt:\n",
    "    gt_tok_dict[tok] += 1\n",
    "  \n",
    "  num_match = 0\n",
    "  \n",
    "  for tok in prd:\n",
    "    if gt_tok_dict[tok] > 0:\n",
    "      num_match += 1\n",
    "      gt_tok_dict[tok] -= 1\n",
    "  \n",
    "  eps = 1e-8\n",
    "  \n",
    "  gt_len = len( [ tok for tok in gt if tok != '<pad>' or tok != 0 ] )\n",
    "  recall = num_match / gt_len if gt_len > 0 else 0\n",
    "  \n",
    "  precision = num_match / len(prd) if len(prd) > 0 else 0\n",
    "  f1 = 2 * (precision * recall) / (precision + recall + eps)\n",
    "  \n",
    "  return precision, recall, f1\n",
    "\n",
    "def calc_all_metrics(gt, prd, encode=True):\n",
    "  gt_dec = tokenizer.decode( gt )\n",
    "  prd_dec = tokenizer.decode( prd )\n",
    "\n",
    "  gt_note, gt_pos, gt_ornament = get_notes_and_positions( gt_dec )\n",
    "  prd_note, prd_pos, prd_ornament = get_notes_and_positions( prd_dec )\n",
    "  \n",
    "  gt_pos, prd_pos = ( filter_pos_list(pl) for pl in (gt_pos, prd_pos) )\n",
    "  \n",
    "  if encode:\n",
    "    gt_note, prd_note = ( tok2idx_list(nl) for nl in ( gt_note, prd_note ) )\n",
    "    gt_pos, prd_pos = ( tok2idx_list(pl, is_pos=True) for pl in ( gt_pos, prd_pos ) )\n",
    "    gt_ornament, prd_ornament = ( [ tok2idx_list(osl) for osl in ol ] for ol in ( gt_ornament, prd_ornament ))\n",
    "  \n",
    "  gt_ornament_flat, prd_ornament_flat = sum(gt_ornament, []), sum(prd_ornament, [])\n",
    "\n",
    "  gt_note_pos = list( zip(gt_note, gt_pos) )\n",
    "  prd_note_pos = list( zip(prd_note, prd_pos) )\n",
    "  \n",
    "  map_ornament_pos = lambda ol, pl: [(o, p) for i, p in enumerate(pl) for o in ol[i]]\n",
    "  map_ornament_note_pos = lambda ol, tl: [ (o, *t) for i, t in enumerate(tl) for o in ol[i]]\n",
    "  \n",
    "  gt_ornament_pos = map_ornament_pos(gt_ornament, gt_pos)\n",
    "  prd_ornament_pos = map_ornamnet_pos(prd_ornament, prd_pos)\n",
    "  \n",
    "  gt_ornament_note_pos = map_ornament_note_pos(gt_ornament, gt_note_pos)\n",
    "  prd_ornament_note_pos = map_ornament_note_pos(prd_ornament, prd_note_pos)\n",
    "  \n",
    "  ner = calc_metric(gt_note, prd_note)\n",
    "  per = calc_metric(gt_pos, prd_pos)\n",
    "  nper = calc_metric(gt_note_pos, prd_note_pos)\n",
    "  \n",
    "  oer = calc_metric(gt_ornament_flat, prd_ornament_flat)\n",
    "  oper = calc_metric(gt_ornament_pos, prd_ornament_pos)\n",
    "  onper = calc_metric(gt_ornament_note_pos, prd_ornament_note_pos)\n",
    "  \n",
    "  return ((gt_note, gt_pos, gt_ornament, gt_note_pos, gt_ornament_pos, gt_ornament_note_pos), (prd_note, prd_pos, prd_ornament, prd_note_pos, prd_ornament_pos, prd_ornament_note_pos)), (ner, per, nper, oer, oper, onper)\n",
    "\n",
    "test_index = 1\n",
    "label, pred = test_ls[test_index][2:4]\n",
    "\n",
    "((label_note, label_pos, label_ornament, label_note_pos, label_ornament_pos, label_ornament_note_pos), (pred_note, pred_pos, pred_ornament, pred_note_pos, pred_ornament_pos, pred_ornament_note_pos)), (ner, per, nper, oer, oper, onper) = calc_all_metrics(label, pred, encode=False)\n",
    "\n",
    "print(calc_metric(label_note, pred_note), label_note, pred_note)\n",
    "print(calc_metric(label_pos, pred_pos), label_pos, pred_pos)\n",
    "print(calc_metric(label_note_pos, pred_note_pos), label_note_pos, pred_note_pos)\n",
    "print(calc_metric(sum(label_ornament, []), sum(pred_ornament, [])), sum(label_ornament, []), sum(pred_ornament, []))\n",
    "print(calc_metric(label_ornament_pos, pred_ornament_pos), label_ornament_pos, pred_ornament_pos)\n",
    "print(calc_metric(label_ornament_note_pos, pred_ornament_note_pos), label_ornament_note_pos, pred_ornament_note_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: with decoded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 0.0833\n",
      "청남_노네:2 -:4 니나*:6 청임:8\n",
      "청남:2 -:4 니나*:6 청임:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['청남', '-', '니나*', '청임']\n",
      "['청남', '-', '니나*', '청임']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['2', '4', '6', '8']\n",
      "['2', '4', '6', '8']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('청남', '2'), ('-', '4'), ('니나*', '6'), ('청임', '8')]\n",
      "[('청남', '2'), ('-', '4'), ('니나*', '6'), ('청임', '8')]\n",
      "OER: (0, 0.0, 0.0)\n",
      "[['_노네'], [], [], []]\n",
      "[[], [], [], []]\n",
      "OPER: (0, 0.0, 0.0)\n",
      "[('_노네', '2')]\n",
      "[]\n",
      "ONPER: (0, 0.0, 0.0)\n",
      "[('_노네', '청남', '2')]\n",
      "[]\n",
      "\n",
      "#1 0.1429\n",
      "고_덧길이표:10 태_반길이표:11\n",
      "고:10 태_반길이표:11\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['고', '태']\n",
      "['고', '태']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['10', '11']\n",
      "['10', '11']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('고', '10'), ('태', '11')]\n",
      "[('고', '10'), ('태', '11')]\n",
      "OER: (1.0, 0.5, 0.6667)\n",
      "[['_덧길이표'], ['_반길이표']]\n",
      "[[], ['_반길이표']]\n",
      "OPER: (1.0, 0.5, 0.6667)\n",
      "[('_덧길이표', '10'), ('_반길이표', '11')]\n",
      "[('_반길이표', '11')]\n",
      "ONPER: (1.0, 0.5, 0.6667)\n",
      "[('_덧길이표', '고', '10'), ('_반길이표', '태', '11')]\n",
      "[('_반길이표', '태', '11')]\n",
      "\n",
      "#2 0.2222\n",
      "황:2 -:5 태_니레:8\n",
      "황:10 태_니레:11\n",
      "NER: (1.0, 0.6667, 0.8)\n",
      "['황', '-', '태']\n",
      "['황', '태']\n",
      "PER: (0.0, 0.0, 0.0)\n",
      "['2', '5', '8']\n",
      "['10', '11']\n",
      "NPER: (0.0, 0.0, 0.0)\n",
      "[('황', '2'), ('-', '5'), ('태', '8')]\n",
      "[('황', '10'), ('태', '11')]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [], ['_니레']]\n",
      "[[], ['_니레']]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[('_니레', '8')]\n",
      "[('_니레', '11')]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[('_니레', '태', '8')]\n",
      "[('_니레', '태', '11')]\n",
      "\n",
      "#3 0.3333\n",
      "황_루러표:5\n",
      "황:5\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['황']\n",
      "['황']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['5']\n",
      "['5']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('황', '5')]\n",
      "[('황', '5')]\n",
      "OER: (0, 0.0, 0.0)\n",
      "[['_루러표']]\n",
      "[[]]\n",
      "OPER: (0, 0.0, 0.0)\n",
      "[('_루러표', '5')]\n",
      "[]\n",
      "ONPER: (0, 0.0, 0.0)\n",
      "[('_루러표', '황', '5')]\n",
      "[]\n",
      "\n",
      "#4 0.4167\n",
      "노:2 -:4 니_미는표:6 느나:8\n",
      "노_미는표:2 -:4 니:6 느나:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['노', '-', '니', '느나']\n",
      "['노', '-', '니', '느나']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['2', '4', '6', '8']\n",
      "['2', '4', '6', '8']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('노', '2'), ('-', '4'), ('니', '6'), ('느나', '8')]\n",
      "[('노', '2'), ('-', '4'), ('니', '6'), ('느나', '8')]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [], ['_미는표'], []]\n",
      "[['_미는표'], [], [], []]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[('_미는표', '6')]\n",
      "[('_미는표', '2')]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[('_미는표', '니', '6')]\n",
      "[('_미는표', '노', '2')]\n",
      "\n",
      "#5 0.5556\n",
      "황:2 -_미는표:5 배중:8\n",
      "황_미는표:2 -:5 배중:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['황', '-', '배중']\n",
      "['황', '-', '배중']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['2', '5', '8']\n",
      "['2', '5', '8']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('황', '2'), ('-', '5'), ('배중', '8')]\n",
      "[('황', '2'), ('-', '5'), ('배중', '8')]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], ['_미는표'], []]\n",
      "[['_미는표'], [], []]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[('_미는표', '5')]\n",
      "[('_미는표', '2')]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[('_미는표', '-', '5')]\n",
      "[('_미는표', '황', '2')]\n",
      "\n",
      "#6 0.6667\n",
      "황_자출:5\n",
      "황_전성:5\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['황']\n",
      "['황']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['5']\n",
      "['5']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('황', '5')]\n",
      "[('황', '5')]\n",
      "OER: (0.0, 0.0, 0.0)\n",
      "[['_자출']]\n",
      "[['_전성']]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[('_자출', '5')]\n",
      "[('_전성', '5')]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[('_자출', '황', '5')]\n",
      "[('_전성', '황', '5')]\n",
      "\n",
      "#7 0.75\n",
      "태:2 -:5 -:7 흘림표_니:9\n",
      "태:2 -:5 -:7 니:9\n",
      "NER: (0.75, 0.75, 0.75)\n",
      "['태', '-', '-', '흘림표']\n",
      "['태', '-', '-', '니']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['2', '5', '7', '9']\n",
      "['2', '5', '7', '9']\n",
      "NPER: (0.75, 0.75, 0.75)\n",
      "[('태', '2'), ('-', '5'), ('-', '7'), ('흘림표', '9')]\n",
      "[('태', '2'), ('-', '5'), ('-', '7'), ('니', '9')]\n",
      "OER: (0, 0.0, 0.0)\n",
      "[[], [], [], ['_니']]\n",
      "[[], [], [], []]\n",
      "OPER: (0, 0.0, 0.0)\n",
      "[('_니', '9')]\n",
      "[]\n",
      "ONPER: (0, 0.0, 0.0)\n",
      "[('_니', '흘림표', '9')]\n",
      "[]\n",
      "\n",
      "#8 0.8889\n",
      "-:2 -_미는표:5 태:8\n",
      "-:2 -_미는표:5 태_시루표:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "['-', '-', '태']\n",
      "['-', '-', '태']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['2', '5', '8']\n",
      "['2', '5', '8']\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[('-', '2'), ('-', '5'), ('태', '8')]\n",
      "[('-', '2'), ('-', '5'), ('태', '8')]\n",
      "OER: (0.5, 1.0, 0.6667)\n",
      "[[], ['_미는표'], []]\n",
      "[[], ['_미는표'], ['_시루표']]\n",
      "OPER: (0.5, 1.0, 0.6667)\n",
      "[('_미는표', '5')]\n",
      "[('_미는표', '5'), ('_시루표', '8')]\n",
      "ONPER: (0.5, 1.0, 0.6667)\n",
      "[('_미는표', '-', '5')]\n",
      "[('_미는표', '-', '5'), ('_시루표', '태', '8')]\n",
      "\n",
      "#9 0.9333\n",
      "배임:2 -:4 태:6 배임:7 황_루러표:9\n",
      "배임:2 -:4 태:6 -:7 황_루러표:9 느나\n",
      "NER: (0.6667, 0.8, 0.7273)\n",
      "['배임', '-', '태', '배임', '황']\n",
      "['배임', '-', '태', '-', '황', '느나']\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "['2', '4', '6', '7', '9']\n",
      "['2', '4', '6', '7', '9']\n",
      "NPER: (0.8, 0.8, 0.8)\n",
      "[('배임', '2'), ('-', '4'), ('태', '6'), ('배임', '7'), ('황', '9')]\n",
      "[('배임', '2'), ('-', '4'), ('태', '6'), ('-', '7'), ('황', '9')]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [], [], [], ['_루러표']]\n",
      "[[], [], [], [], ['_루러표'], []]\n",
      "OPER: (1.0, 1.0, 1.0)\n",
      "[('_루러표', '9')]\n",
      "[('_루러표', '9')]\n",
      "ONPER: (1.0, 1.0, 1.0)\n",
      "[('_루러표', '황', '9')]\n",
      "[('_루러표', '황', '9')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, test_case in enumerate(test_ls):\n",
    "  label, pred = test_case[2:4]\n",
    "\n",
    "  label_dec = tokenizer.decode( label )\n",
    "  pred_dec = tokenizer.decode( pred )\n",
    "\n",
    "  ((label_note, label_pos, label_ornament, label_note_pos, label_ornament_pos, label_ornament_note_pos), (pred_note, pred_pos, pred_ornament, pred_note_pos, pred_ornament_pos, pred_ornament_note_pos)), (ner, per, nper, oer, oper, onper) = calc_all_metrics(label, pred, encode=False)\n",
    "  \n",
    "  round_tuple_el = lambda t: tuple(map(lambda x: round(x, 4), t))\n",
    "  \n",
    "  ner, per, nper, oer, oper, onper = ( round_tuple_el(mv) for mv in (ner, per, nper, oer, oper, onper) )\n",
    "\n",
    "  print(f'#{idx} {round(test_case[4], 4)}')\n",
    "  print(label_dec)\n",
    "  print(pred_dec)\n",
    "  print(f'NER: {ner}')\n",
    "  print(label_note)\n",
    "  print(pred_note)\n",
    "  print(f'PER: {per}')\n",
    "  print(label_pos)\n",
    "  print(pred_pos)\n",
    "  print(f'NPER: {nper}')\n",
    "  print(label_note_pos)\n",
    "  print(pred_note_pos)\n",
    "  print(f'OER: {oer}')\n",
    "  print(label_ornament)\n",
    "  print(pred_ornament)\n",
    "  print(f'OPER: {oper}')\n",
    "  print(label_ornament_pos)\n",
    "  print(pred_ornament_pos)\n",
    "  print(f'ONPER: {onper}')\n",
    "  print(label_ornament_note_pos)\n",
    "  print(pred_ornament_note_pos)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: with encoded indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 0.0833\n",
      "청남_노네:2 -:4 니나*:6 청임:8\n",
      "청남:2 -:4 니나*:6 청임:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[119, 4, 89, 121]\n",
      "[119, 4, 89, 121]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[12, 14, 16, 18]\n",
      "[12, 14, 16, 18]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(119, 12), (4, 14), (89, 16), (121, 18)]\n",
      "[(119, 12), (4, 14), (89, 16), (121, 18)]\n",
      "OER: (0, 0.0, 0.0)\n",
      "[[34], [], [], []]\n",
      "[[], [], [], []]\n",
      "OPER: (0, 0.0, 0.0)\n",
      "[(34, 12)]\n",
      "[]\n",
      "ONPER: (0, 0.0, 0.0)\n",
      "[(34, 119, 12)]\n",
      "[]\n",
      "\n",
      "#1 0.1429\n",
      "고_덧길이표:10 태_반길이표:11\n",
      "고:10 태_반길이표:11\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[76, 127]\n",
      "[76, 127]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[6, 7]\n",
      "[6, 7]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(76, 6), (127, 7)]\n",
      "[(76, 6), (127, 7)]\n",
      "OER: (1.0, 0.5, 0.6667)\n",
      "[[52], [58]]\n",
      "[[], [58]]\n",
      "OPER: (1.0, 0.5, 0.6667)\n",
      "[(52, 6), (58, 7)]\n",
      "[(58, 7)]\n",
      "ONPER: (1.0, 0.5, 0.6667)\n",
      "[(52, 76, 6), (58, 127, 7)]\n",
      "[(58, 127, 7)]\n",
      "\n",
      "#2 0.2222\n",
      "황:2 -:5 태_니레:8\n",
      "황:10 태_니레:11\n",
      "NER: (1.0, 0.6667, 0.8)\n",
      "[140, 4, 127]\n",
      "[140, 127]\n",
      "PER: (0.0, 0.0, 0.0)\n",
      "[12, 15, 18]\n",
      "[6, 7]\n",
      "NPER: (0.0, 0.0, 0.0)\n",
      "[(140, 12), (4, 15), (127, 18)]\n",
      "[(140, 6), (127, 7)]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [], [49]]\n",
      "[[], [49]]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[(49, 18)]\n",
      "[(49, 7)]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[(49, 127, 18)]\n",
      "[(49, 127, 7)]\n",
      "\n",
      "#3 0.3333\n",
      "황_루러표:5\n",
      "황:5\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[140]\n",
      "[140]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[15]\n",
      "[15]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(140, 15)]\n",
      "[(140, 15)]\n",
      "OER: (0, 0.0, 0.0)\n",
      "[[55]]\n",
      "[[]]\n",
      "OPER: (0, 0.0, 0.0)\n",
      "[(55, 15)]\n",
      "[]\n",
      "ONPER: (0, 0.0, 0.0)\n",
      "[(55, 140, 15)]\n",
      "[]\n",
      "\n",
      "#4 0.4167\n",
      "노:2 -:4 니_미는표:6 느나:8\n",
      "노_미는표:2 -:4 니:6 느나:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[80, 4, 87, 83]\n",
      "[80, 4, 87, 83]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[12, 14, 16, 18]\n",
      "[12, 14, 16, 18]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(80, 12), (4, 14), (87, 16), (83, 18)]\n",
      "[(80, 12), (4, 14), (87, 16), (83, 18)]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [], [57], []]\n",
      "[[57], [], [], []]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[(57, 16)]\n",
      "[(57, 12)]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[(57, 87, 16)]\n",
      "[(57, 80, 12)]\n",
      "\n",
      "#5 0.5556\n",
      "황:2 -_미는표:5 배중:8\n",
      "황_미는표:2 -:5 배중:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[140, 4, 106]\n",
      "[140, 4, 106]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[12, 15, 18]\n",
      "[12, 15, 18]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(140, 12), (4, 15), (106, 18)]\n",
      "[(140, 12), (4, 15), (106, 18)]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [57], []]\n",
      "[[57], [], []]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[(57, 15)]\n",
      "[(57, 12)]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[(57, 4, 15)]\n",
      "[(57, 140, 12)]\n",
      "\n",
      "#6 0.6667\n",
      "황_자출:5\n",
      "황_전성:5\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[140]\n",
      "[140]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[15]\n",
      "[15]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(140, 15)]\n",
      "[(140, 15)]\n",
      "OER: (0.0, 0.0, 0.0)\n",
      "[[67]]\n",
      "[[68]]\n",
      "OPER: (0.0, 0.0, 0.0)\n",
      "[(67, 15)]\n",
      "[(68, 15)]\n",
      "ONPER: (0.0, 0.0, 0.0)\n",
      "[(67, 140, 15)]\n",
      "[(68, 140, 15)]\n",
      "\n",
      "#7 0.75\n",
      "태:2 -:5 -:7 흘림표_니:9\n",
      "태:2 -:5 -:7 니:9\n",
      "NER: (0.75, 0.75, 0.75)\n",
      "[127, 4, 4, 141]\n",
      "[127, 4, 4, 87]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[12, 15, 17, 19]\n",
      "[12, 15, 17, 19]\n",
      "NPER: (0.75, 0.75, 0.75)\n",
      "[(127, 12), (4, 15), (4, 17), (141, 19)]\n",
      "[(127, 12), (4, 15), (4, 17), (87, 19)]\n",
      "OER: (0, 0.0, 0.0)\n",
      "[[], [], [], [47]]\n",
      "[[], [], [], []]\n",
      "OPER: (0, 0.0, 0.0)\n",
      "[(47, 19)]\n",
      "[]\n",
      "ONPER: (0, 0.0, 0.0)\n",
      "[(47, 141, 19)]\n",
      "[]\n",
      "\n",
      "#8 0.8889\n",
      "-:2 -_미는표:5 태:8\n",
      "-:2 -_미는표:5 태_시루표:8\n",
      "NER: (1.0, 1.0, 1.0)\n",
      "[4, 4, 127]\n",
      "[4, 4, 127]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[12, 15, 18]\n",
      "[12, 15, 18]\n",
      "NPER: (1.0, 1.0, 1.0)\n",
      "[(4, 12), (4, 15), (127, 18)]\n",
      "[(4, 12), (4, 15), (127, 18)]\n",
      "OER: (0.5, 1.0, 0.6667)\n",
      "[[], [57], []]\n",
      "[[], [57], [64]]\n",
      "OPER: (0.5, 1.0, 0.6667)\n",
      "[(57, 15)]\n",
      "[(57, 15), (64, 18)]\n",
      "ONPER: (0.5, 1.0, 0.6667)\n",
      "[(57, 4, 15)]\n",
      "[(57, 4, 15), (64, 127, 18)]\n",
      "\n",
      "#9 0.9333\n",
      "배임:2 -:4 태:6 배임:7 황_루러표:9\n",
      "배임:2 -:4 태:6 -:7 황_루러표:9 느나\n",
      "NER: (0.6667, 0.8, 0.7273)\n",
      "[105, 4, 127, 105, 140]\n",
      "[105, 4, 127, 4, 140, 83]\n",
      "PER: (1.0, 1.0, 1.0)\n",
      "[12, 14, 16, 17, 19]\n",
      "[12, 14, 16, 17, 19]\n",
      "NPER: (0.8, 0.8, 0.8)\n",
      "[(105, 12), (4, 14), (127, 16), (105, 17), (140, 19)]\n",
      "[(105, 12), (4, 14), (127, 16), (4, 17), (140, 19)]\n",
      "OER: (1.0, 1.0, 1.0)\n",
      "[[], [], [], [], [55]]\n",
      "[[], [], [], [], [55], []]\n",
      "OPER: (1.0, 1.0, 1.0)\n",
      "[(55, 19)]\n",
      "[(55, 19)]\n",
      "ONPER: (1.0, 1.0, 1.0)\n",
      "[(55, 140, 19)]\n",
      "[(55, 140, 19)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, test_case in enumerate(test_ls):\n",
    "  label, pred = test_case[2:4]\n",
    "\n",
    "  label_dec = tokenizer.decode( label )\n",
    "  pred_dec = tokenizer.decode( pred )\n",
    "\n",
    "  ((label_note, label_pos, label_ornament, label_note_pos, label_ornament_pos, label_ornament_note_pos), (pred_note, pred_pos, pred_ornament, pred_note_pos, pred_ornament_pos, pred_ornament_note_pos)), (ner, per, nper, oer, oper, onper) = calc_all_metrics(label, pred, encode=True)\n",
    "  \n",
    "  round_tuple_el = lambda t: tuple(map(lambda x: round(x, 4), t))\n",
    "  \n",
    "  ner, per, nper, oer, oper, onper = ( round_tuple_el(mv) for mv in (ner, per, nper, oer, oper, onper) )\n",
    "\n",
    "  print(f'#{idx} {round(test_case[4], 4)}')\n",
    "  print(label_dec)\n",
    "  print(pred_dec)\n",
    "  print(f'NER: {ner}')\n",
    "  print(label_note)\n",
    "  print(pred_note)\n",
    "  print(f'PER: {per}')\n",
    "  print(label_pos)\n",
    "  print(pred_pos)\n",
    "  print(f'NPER: {nper}')\n",
    "  print(label_note_pos)\n",
    "  print(pred_note_pos)\n",
    "  print(f'OER: {oer}')\n",
    "  print(label_ornament)\n",
    "  print(pred_ornament)\n",
    "  print(f'OPER: {oper}')\n",
    "  print(label_ornament_pos)\n",
    "  print(pred_ornament_pos)\n",
    "  print(f'ONPER: {onper}')\n",
    "  print(label_ornament_note_pos)\n",
    "  print(pred_ornament_note_pos)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n"
     ]
    }
   ],
   "source": [
    "for q, v in enumerate( (1, 2, 3, 4) ):\n",
    "  print(q, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 3, 1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [1, 2, 3]\n",
    "temp *= 3\n",
    "\n",
    "temp[0] = 4\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...data_set loading...\n",
      "COMPLETE: data_set loading\n",
      "\n",
      "...tokenizer loading...\n",
      "COMPLETE: load tokenizer\n",
      "\n",
      "...model initializing...\n",
      "COMPLETE: model initializing\n",
      "\n",
      "...testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_all': 0.8610526315789473, 'exact_pos': 0.9450827067669173, 'exact_note': 0.9392631578947368, 'exact_length': 0.9500225563909774, 'note_pitch': 0.9958318735678708, 'note_pcalss': 0.9977233327777721}\n",
      "exact_all\n",
      "COMPLETE: Testing\n",
      "\n",
      "...processing test result...\n",
      "COMPLETE: processing test result\n",
      "\n",
      "...calculating metrics...\n",
      "1532\n",
      "6\n",
      "1532\n",
      "3\n",
      "[0.9858388950245259, 0.985482524532533, 0.9781987110326292, 0.5130657067076098, 0.49333115500794245, 0.4911553499724041]\n",
      "COMPLETE: calculating metrics\n"
     ]
    }
   ],
   "source": [
    "def test(project_root_dir, exp_dir, csv_path):\n",
    "  conf = OmegaConf.load(exp_dir / '.hydra' / 'config.yaml')\n",
    "  device = torch.device(conf.general.device)\n",
    "\n",
    "  print('\\n...data_set loading...')\n",
    "  test_set = LabelStudioDataset(project_root_dir / conf.data_path.test, project_root_dir / 'jeongganbo-png/splited-pngs', remove_borders=conf.test_setting.remove_borders, is_valid=True)\n",
    "  test_loader = DataLoader(test_set, batch_size=1000, shuffle=False, collate_fn=pad_collate, num_workers=conf.dataloader.num_workers_load)\n",
    "\n",
    "  print('COMPLETE: data_set loading')\n",
    "\n",
    "  model_dir = exp_dir / 'model'\n",
    "\n",
    "  print('\\n...tokenizer loading...')\n",
    "\n",
    "  tokenizer_vocab_fn = model_dir / f'{conf.general.model_name}_tokenizer.txt'\n",
    "  tokenizer = Tokenizer(vocab_txt_fn=tokenizer_vocab_fn)\n",
    "  \n",
    "  test_set.tokenizer = tokenizer\n",
    "\n",
    "  print('COMPLETE: load tokenizer')\n",
    "\n",
    "  print('\\n...model initializing...')\n",
    "  model = TransformerOMR(conf.model.dim, len(tokenizer.vocab), enc_depth=conf.model.enc_depth, dec_depth=conf.model.dec_depth, num_heads=conf.model.num_heads, dropout=conf.model.dropout)\n",
    "  model.load_state_dict(torch.load(model_dir / f'{conf.general.model_name}_HL_{conf.test_setting.target_metric}_best.pt', map_location='cpu')['model'])\n",
    "\n",
    "  tester = Trainer(model, \n",
    "                  None, #optimizer\n",
    "                  None, #loss_fn\n",
    "                  None, #train_loader\n",
    "                  test_loader, \n",
    "                  tokenizer,\n",
    "                  device=device, \n",
    "                  scheduler=None,\n",
    "                  aux_loader=None,\n",
    "                  aux_freq=None,\n",
    "                  mix_aux=None,\n",
    "                  aux_valid_loader=None,\n",
    "                  wandb=None, \n",
    "                  model_name=conf.general.model_name,\n",
    "                  model_save_path=model_dir,\n",
    "                  checkpoint_logger=None)\n",
    "\n",
    "  print('COMPLETE: model initializing')\n",
    "\n",
    "  print('\\n...testing...')\n",
    "\n",
    "  _, metric_dict, pred_tensor_list, _ = tester.validate(with_confidence=True)\n",
    "  \n",
    "  print(metric_dict)\n",
    "  print(conf.test_setting.target_metric)\n",
    "\n",
    "  print('COMPLETE: Testing')\n",
    "  \n",
    "  print('\\n...processing test result...')\n",
    "  \n",
    "  pred_list = []\n",
    "\n",
    "  for b_idx in range(len(pred_tensor_list)):\n",
    "    pred_list += pred_tensor_list[b_idx].tolist()\n",
    "\n",
    "  pred_list = list( enumerate(pred_list) )\n",
    "  pred_list = make_gt_pred_tuple_list(pred_list)\n",
    "  \n",
    "  print('COMPLETE: processing test result')\n",
    "  \n",
    "  print('\\n...calculating metrics...')\n",
    "  \n",
    "  num_total_case = 0\n",
    "  num_metrics = 6\n",
    "  metric_ls = [ [] for _ in range(6) ] # ner, per, nper, oer, oper, onper\n",
    "  \n",
    "  for case in pred_list:\n",
    "    label, pred = case[2:4]\n",
    "    \n",
    "    _, new_metric = calc_all_metrics(label, pred, encode=True)\n",
    "    \n",
    "    for m_idx, nmt in enumerate(new_metric):\n",
    "      metric_ls[m_idx].append(nmt)    \n",
    "    \n",
    "    num_total_case += 1\n",
    "  \n",
    "  print(num_total_case)\n",
    "  print(len(metric_ls)) # should be 6\n",
    "  print(len(metric_ls[1])) # should be the same as num_total_case\n",
    "  print(len(metric_ls[0][0])) # 3\n",
    "  \n",
    "  metric_values = []\n",
    "  \n",
    "  for mvl in metric_ls:\n",
    "    avg_ls = []\n",
    "    \n",
    "    for i in range(3):\n",
    "      [mt[i] for mt in mvl]\n",
    "      avg_ls.append( sum([mt[i] for mt in mvl]) / num_total_case )\n",
    "    \n",
    "    metric_values.append(tuple(avg_ls))\n",
    "  \n",
    "  exact_all = metric_dict[conf.test_setting.target_metric]\n",
    "  \n",
    "  print([ mv[2] for mv in metric_values ])\n",
    "  \n",
    "  with open(csv_path, 'a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # writer.writerow([conf.general.model_name, metric_dict[conf.test_setting.target_metric]] + metric_values)\n",
    "    writer.writerow( [conf.general.model_name, exact_all] + [mv[2] for mv in metric_values] )\n",
    "  \n",
    "  print('COMPLETE: calculating metrics')\n",
    "\n",
    "project_root_dir = Path('.')\n",
    "output_dir = project_root_dir / 'outputs'\n",
    "dir_date = '2024-05-04'\n",
    "dir_time = '20-31-38'\n",
    "\n",
    "exp_dir = output_dir / dir_date / dir_time  \n",
    "\n",
    "csv_path = project_root_dir / 'test' / 'new_metric_test.csv'\n",
    "\n",
    "pred_list = test(project_root_dir, exp_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "for i in range(3):\n",
    "  temp.append((1, 2, 3))\n",
    "\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(), (), (), (), (), ()]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[()] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "황:5\n",
      "황:5\n",
      "((1.0, 1.0, 0.999999995), (1.0, 1.0, 0.999999995), (1.0, 1.0, 0.999999995), (0, 0, 0.0), (0, 0, 0.0), (0, 0, 0.0))\n",
      "겹요성표:5\n",
      "겹요성표:5\n",
      "((1.0, 1.0, 0.999999995), (1.0, 1.0, 0.999999995), (1.0, 1.0, 0.999999995), (0, 0, 0.0), (0, 0, 0.0), (0, 0, 0.0))\n",
      "2\n",
      "6\n",
      "2\n",
      "3\n",
      "((1.0, 1.0, 0.999999995), (1.0, 1.0, 0.999999995))\n"
     ]
    }
   ],
   "source": [
    "num_total_case = 0\n",
    "num_metrics = 6\n",
    "metric_ls = [()] * num_metrics # ner, per, nper, oer, oper, onper\n",
    "\n",
    "for case in pred_list[:2]:\n",
    "  label, pred = case[2:4]\n",
    "  \n",
    "  print(tokenizer.decode(label))\n",
    "  print(tokenizer.decode(pred))\n",
    "  \n",
    "  _, new_metric = calc_all_metrics(label, pred, encode=True)\n",
    "  print(new_metric)\n",
    "  \n",
    "  for m_idx in range(num_metrics):\n",
    "    m_t = new_metric[m_idx]\n",
    "    m_ls = list(metric_ls[m_idx])\n",
    "    m_ls += [m_t]\n",
    "    \n",
    "    metric_ls[m_idx] = tuple(m_ls)\n",
    "  \n",
    "  num_total_case += 1\n",
    "\n",
    "print(num_total_case)\n",
    "print(len(metric_ls)) # should be 6\n",
    "print(len(metric_ls[0])) # should be the same as num_total_case\n",
    "print(len(metric_ls[0][0])) # 3\n",
    "print(metric_ls[0])\n",
    "\n",
    "metric_values = []\n",
    "\n",
    "for mvl in metric_ls:\n",
    "  avg_ls = []\n",
    "  \n",
    "  for i in range(3):\n",
    "    [mt[i] for mt in mvl]\n",
    "    avg_ls.append( sum([mt[i] for mt in mvl]) / num_total_case )\n",
    "  \n",
    "  metric_values.append(tuple(avg_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dates = ['2024-05-03', '2024-05-04']\n",
    "dir_times = [\n",
    "  [\n",
    "    '21-55-11', \n",
    "    '22-41-31', \n",
    "    '23-27-48', \n",
    "  ],\n",
    "  [\n",
    "    '00-14-10', \n",
    "    '01-48-46', \n",
    "    '03-22-26', \n",
    "    '04-55-03', \n",
    "    '06-29-30', \n",
    "    '08-02-58', \n",
    "    '09-35-37', \n",
    "    '11-10-10', \n",
    "    '12-43-58', \n",
    "    '14-16-32', \n",
    "    '15-50-51', \n",
    "    '17-24-27', \n",
    "    '18-57-02', \n",
    "    '20-31-38', \n",
    "    '01-01-26', \n",
    "    '02-36-04', \n",
    "    '04-08-48', \n",
    "    '05-42-17', \n",
    "    '07-16-44', \n",
    "    '08-49-17', \n",
    "    '10-22-54', \n",
    "    '11-57-33', \n",
    "    '13-30-12', \n",
    "    '15-03-40', \n",
    "    '16-38-09', \n",
    "    '18-10-43', \n",
    "    '19-44-22',     \n",
    "    '20-31-38',\n",
    "  ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...tokenizer loading...\n",
      "COMPLETE: load tokenizer\n",
      "\n",
      "...data_set loading...\n",
      "COMPLETE: data_set loading\n",
      "\n",
      "...model initializing...\n",
      "COMPLETE: model initializing\n",
      "\n",
      "...testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE: Testing\n",
      "\n",
      "...processing test result...\n",
      "COMPLETE: processing test result\n",
      "\n",
      "...calculating metrics...\n",
      "COMPLETE: calculating metrics\n"
     ]
    }
   ],
   "source": [
    "from test_new_metric import test as new_test\n",
    "\n",
    "project_root_dir = Path('.')\n",
    "output_dir = project_root_dir / 'outputs'\n",
    "csv_path = project_root_dir / 'test' / 'new_metric_test.csv'\n",
    "\n",
    "dir_date, dir_time = (dir_dates[1], dir_times[1][-1])\n",
    "\n",
    "exp_dir = output_dir / dir_date / dir_time  \n",
    "new_test(project_root_dir, exp_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'enumerate' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m project_root_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m project_root_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_metric_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date_idx, dir_date \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdir_dates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m dir_time \u001b[38;5;129;01min\u001b[39;00m dir_times[date_idx][:\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     10\u001b[0m     exp_dir \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;241m/\u001b[39m dir_date \u001b[38;5;241m/\u001b[39m dir_time  \n",
      "\u001b[0;31mTypeError\u001b[0m: 'enumerate' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from test_new_metric import test as new_test\n",
    "\n",
    "project_root_dir = Path('.')\n",
    "output_dir = project_root_dir / 'outputs'\n",
    "csv_path = project_root_dir / 'test' / 'new_metric_test.csv'\n",
    "\n",
    "for date_idx, dir_date in enumerate(dir_dates):\n",
    "  for dir_time in dir_times[date_idx]:\n",
    "    \n",
    "    exp_dir = output_dir / dir_date / dir_time  \n",
    "    new_test(project_root_dir, exp_dir, csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeongganbo-omr-QQMBMPoZ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
